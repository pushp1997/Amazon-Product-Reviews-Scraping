{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Product Review Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to scrape reviews of any product link provided using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture requirements\n",
    "import sys\n",
    "import os\n",
    "!{sys.executable} -m pip install bs4\n",
    "!{sys.executable} -m pip install lxml\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install dateparser\n",
    "import dateparser\n",
    "import time\n",
    "import requests\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_page(link):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; U; Linux i686; en-US) AppleWebKit/534.3 (KHTML, like Gecko) Chrome/6.0.472.64 Safari/534.3'}\n",
    "    page = requests.get(link, headers=headers)\n",
    "    return BeautifulSoup(page.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product link: https://www.amazon.in/Test-Exclusive-608/dp/B07HGBMJT6/ref=sr_1_1?keywords=oneplus+7&qid=1563085781&s=gateway&smid=A35FCS7U51TK3C&sr=8-1\n",
      "https://www.amazon.in\n"
     ]
    }
   ],
   "source": [
    "product_link = input('Enter the product link: ')\n",
    "relative_url_prefix = \"/\".join(product_link.split(\"/\", 3)[:3])\n",
    "print(relative_url_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_page_soup = get_page(product_link)\n",
    "#print(product_page_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in/Test-Exclusive-608/product-reviews/B07HGBMJT6/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\n"
     ]
    }
   ],
   "source": [
    "see_all_reviews = product_page_soup.find_all(\"a\", {\"data-hook\" : \"see-all-reviews-link-foot\"})[0]\n",
    "all_reviews_url =  relative_url_prefix + see_all_reviews['href']\n",
    "print(all_reviews_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_page_limit = 5\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "csvoutput_file = f'.{os.path.sep}review_{timestr}.csv'\n",
    "\n",
    "all_reviews_page_soup = get_page(all_reviews_url)\n",
    "\n",
    "def parse_review_date(review_date_text):\n",
    "    reduced_date_text = \" \".join(review_date_text.split()[-3:])\n",
    "    return dateparser.parse(reduced_date_text).isoformat()\n",
    "\n",
    "def parse_reviews(soup):\n",
    "    parsed = []\n",
    "    for review in soup.find_all(\"div\", {\"data-hook\" : \"review\"}):\n",
    "        try:\n",
    "            parsed.append({\n",
    "                'id': review['id'],\n",
    "                'name': review.find(\"span\", {\"class\" : \"a-profile-name\"}).text,\n",
    "                'rating': review.find(class_='a-section celwidget').find(class_='a-icon-alt').text[:3],\n",
    "                'title': review.find(\"a\", {\"data-hook\" : \"review-title\"}).find(\"span\").text,\n",
    "                'date': parse_review_date(review.find(\"span\", {\"data-hook\" : \"review-date\"}).text),\n",
    "                'text': review.find(\"span\", {\"data-hook\": \"review-body\"}).find(\"span\").text.strip()\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    #print(parsed)\n",
    "    #print(len(parsed))\n",
    "    return parsed\n",
    "\n",
    "def has_next_page(soup):\n",
    "    return relative_url_prefix + soup.find(\"li\", { \"class\" : \"a-last\"}).find(\"a\")[\"href\"]\n",
    "\n",
    "def append_to_csv(list):\n",
    "    pd.DataFrame(list).to_csv(csvoutput_file, mode='a', index=False, header=False)\n",
    "\n",
    "try:\n",
    "    page_counter = 0\n",
    "    parsed_page = parse_reviews(all_reviews_page_soup)\n",
    "    append_to_csv(parsed_page)\n",
    "    \n",
    "    # get next page\n",
    "    while True:\n",
    "        page_counter += 1\n",
    "        if page_counter >= review_page_limit:\n",
    "            break\n",
    "\n",
    "        next_page_link = has_next_page(all_reviews_page_soup)\n",
    "        #print(next_page_link)\n",
    "        if not next_page_link:\n",
    "            break\n",
    "\n",
    "        all_reviews_page_soup = get_page(next_page_link)\n",
    "        parsed_page = parse_reviews(all_reviews_page_soup)\n",
    "        append_to_csv(parsed_page)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the the Reviews dataframe to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
